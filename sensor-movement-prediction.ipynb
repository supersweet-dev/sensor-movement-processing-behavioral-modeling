{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 62.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.20.2 pandas-1.2.4\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 46.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 56.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=ea25b7262c62c6b8edb3cd59880d40e618408865c045c2801a4267268cab0265\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 scipy-1.6.3 sklearn-0.0 threadpoolctl-2.1.0\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.20.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 42.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 58.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.1 pillow-8.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pandas library helps parse CSV files, or files delimited by specific character.\n",
    "# In this case we use pandas to process our training and test data so we can easily feed it into our program.\n",
    "import pandas as pd\n",
    "\n",
    "# From tree we take the DTC class, which will create a decision tree trained with our data.\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn import tree\n",
    "# From metrics we use acuracy_score to test our outcome against our expectations.\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constant global variables, labels for our CSV since it has no headers,\n",
    "# the labels we'll use for training, and an array to hold the performance scores\n",
    "featureNames2sensor = [\"sd_front\", \"sd_left\"]\n",
    "featureNames4sensor = [\"sd_front\", \"sd_left\", \"sd_right\", \"sd_back\"]\n",
    "featureNames24sensor = [(\"US\"+ str(x)) for x in range(1, 24)]\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to parse our datafiles using Pandas, returns a data frame. It works for training and test sets.\n",
    "def getDataSet(filename, featureNames):\n",
    "    # We specify that there's no index column and feed our header names so the values process\n",
    "    # as we expect them to.\n",
    "    colNames = featureNames + [\"move\"]\n",
    "    dataset = pd.read_csv(filename, index_col=None, header=None, names=colNames)\n",
    "    classes = [\n",
    "        \"Move-Forward\",\n",
    "        \"Slight-Right-Turn\",\n",
    "        \"Sharp-Right-Turn\",\n",
    "        \"Slight-Left-Turn\",\n",
    "    ]\n",
    "    # We simplify our \"label\" field, which is our goal, using a simple function that returns a number representing one of the 4 possible moves\n",
    "    dataset[\"move\"] = dataset[\"move\"].map(lambda n: classes.index(n) + 1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTest(numSensors, featureNames):\n",
    "    # We call our get set function to generate the sets we'll be using through the program.\n",
    "    trainingset = getDataSet(\"sensor_readings_\" + str(numSensors) + \"_training.csv\", featureNames)\n",
    "    testset = getDataSet(\"sensor_readings_\" + str(numSensors) + \"_test.csv\", featureNames)\n",
    "    \n",
    "    # We use the DecisionTreeClassifier constructor to generate a DTC using entropy to decide on splits.\n",
    "    # We feed it our training set and the associated goals to train it.\n",
    "    moveDecider = dtc(criterion=\"entropy\").fit(trainingset[featureNames], trainingset.move)\n",
    "    # To test it, we feed it out test set and it returns an array of predictions.\n",
    "    testPredictions = moveDecider.predict(testset[featureNames])\n",
    "    # We compare our result to our expectations (the test set goals) and store the percentage in our score array.\n",
    "    currentScore = metrics.accuracy_score(testset.move, testPredictions)\n",
    "    scores.append(currentScore)\n",
    "    figName = str(numSensors) + \"-sensor-dtc.png\"\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    tree.plot_tree(moveDecider)\n",
    "    fig.savefig(figName)\n",
    "    fig.clf()\n",
    "    print(\"Tree saved as \" + figName)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree saved as 2-sensor-dtc.png\n",
      "Accuracy for intial Decision Tree for 2 sensor data: 1.0\n",
      "a score of 1 means our predictions were perfect.\n",
      "Tree saved as 4-sensor-dtc.png\n",
      "Accuracy for intial Decision Tree for 4 sensor data: 1.0\n",
      "a score of 1 means our predictions were perfect.\n",
      "Tree saved as 24-sensor-dtc.png\n",
      "Accuracy for intial Decision Tree for 24 sensor data: 0.9693287037037037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runTest(2, featureNames2sensor)\n",
    "print(\"Accuracy for intial Decision Tree for 2 sensor data:\", scores[0])\n",
    "if scores[0] == 1.0:\n",
    "    print(\"a score of 1 means our predictions were perfect.\")\n",
    "runTest(4, featureNames4sensor)\n",
    "print(\"Accuracy for intial Decision Tree for 4 sensor data:\", scores[1])\n",
    "if scores[1] == 1.0:\n",
    "    print(\"a score of 1 means our predictions were perfect.\")\n",
    "runTest(24, featureNames24sensor)\n",
    "print(\"Accuracy for intial Decision Tree for 24 sensor data:\", scores[2])\n",
    "if scores[2] == 1.0:\n",
    "    print(\"a score of 1 means our predictions were perfect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "deciders = [\"2 sensor\", \"4 sensor\", \"24 sensor\"]\n",
    "ax.bar(deciders, scores)\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_xlabel(\"Accuracy %\")\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_title(\"Classifier Scores in %\")\n",
    "fig.savefig(\"sensor-comparisson.png\", bbox_inches=\"tight\")\n",
    "\n",
    "fig.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "b966c0226cd4c4e1100ebce742c7ddedf8ad97d1bea1f6a1ab41fc2b092f94b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
